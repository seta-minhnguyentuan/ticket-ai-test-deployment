{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from bottle import Bottle, request, response, run, static_file\n",
    "import openai\n",
    "from google.cloud import bigquery, storage\n",
    "from markdown_it import MarkdownIt\n",
    "\n",
    "# Initialize bottle app\n",
    "app = Bottle()\n",
    "\n",
    "# Setup markdown parser\n",
    "md = MarkdownIt()\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"openai_api_key\": os.environ.get(\"OPENAI_API_KEY\", \"\"),\n",
    "    \"gcp_project_id\": os.environ.get(\"GCP_PROJECT_ID\", \"\"),\n",
    "    \"storage_bucket\": os.environ.get(\"STORAGE_BUCKET\", \"api_logs\"),\n",
    "    \"static_folder\": os.path.join(os.getcwd(), \"Static\")\n",
    "}\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai.api_key = config[\"openai_api_key\"]\n",
    "\n",
    "# Initialize GCP clients if credentials are available\n",
    "bigquery_client = None\n",
    "storage_client = None\n",
    "try:\n",
    "    bigquery_client = bigquery.Client()\n",
    "    storage_client = storage.Client()\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not initialize GCP clients: {e}\")\n",
    "\n",
    "# Serve static files\n",
    "@app.route('/static/<filepath:path>')\n",
    "def serve_static(filepath):\n",
    "    return static_file(filepath, root=config[\"static_folder\"])\n",
    "\n",
    "# Serve favicon\n",
    "@app.route('/favicon.ico')\n",
    "def favicon():\n",
    "    return static_file('favicon.ico', root=config[\"static_folder\"])\n",
    "\n",
    "# Root endpoint\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return static_file('index.html', root=config[\"static_folder\"])\n",
    "\n",
    "# Health check endpoint\n",
    "@app.route('/health')\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\", \"version\": \"1.0.0\"}\n",
    "\n",
    "# Ticket processing endpoint\n",
    "@app.route('/process_ticket', method='POST')\n",
    "def process_ticket():\n",
    "    try:\n",
    "        data = request.json\n",
    "        query = data.get('query', '')\n",
    "        response_type = data.get('responseType', 'customer')\n",
    "        deployment = data.get('deployment', 'gpt-3.5-turbo')\n",
    "        agent_name = data.get('agentName', '')\n",
    "        ticket_number = data.get('ticketNumber', '')\n",
    "        \n",
    "        if not query:\n",
    "            response.status = 400\n",
    "            return {\"error\": \"No query provided\"}\n",
    "        \n",
    "        # Start time for processing\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Read sample response from Test.md\n",
    "        with open(os.path.join(os.getcwd(), 'Test.md'), 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Extract customer response from markdown file\n",
    "        import re\n",
    "        customer_response_match = re.search(r'### Customer response:\\s*\"(.+?)\"', content, re.DOTALL)\n",
    "        customer_response = customer_response_match.group(1).strip() if customer_response_match else \"Thank you for your query. We'll get back to you soon.\"\n",
    "        \n",
    "        # Generate a session ID for tracking\n",
    "        query_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Mock data\n",
    "        vehicleSubscriptionResponse = \"Vehicle: Mitsubishi Outlander 2023\\nVIN: ABC123456789\\nSubscription: Active\\nExpiry: 2025-12-31\"\n",
    "        debugResponse = json.dumps({\n",
    "            \"query\": query,\n",
    "            \"model\": deployment,\n",
    "            \"processingSteps\": [\"Parse query\", \"Extract context\", \"Generate response\"]\n",
    "        })\n",
    "        SW_INFO = \"TicketAI for Finch (v1.11.0)\"\n",
    "        reply_role = response_type\n",
    "        runtime = datetime.now() - start_time\n",
    "        processing_time = runtime\n",
    "        user_query = query\n",
    "        \n",
    "        return {\n",
    "            'customerResponse': customer_response,\n",
    "            'vehicleSubscriptionResponse': vehicleSubscriptionResponse,\n",
    "            'debugResponse': debugResponse,\n",
    "            'sessionId': query_id,\n",
    "            'SW_INFO': SW_INFO,\n",
    "            'processing_time': processing_time.total_seconds(),\n",
    "            'Role': reply_role,\n",
    "            'run_time': runtime.total_seconds(),\n",
    "            'customerQuery': user_query\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        response.status = 500\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Process rating feedback\n",
    "@app.route('/process_rating', method='POST')\n",
    "def process_rating():\n",
    "    try:\n",
    "        data = request.json\n",
    "        name = data.get('name', '')\n",
    "        ticket = data.get('ticket', '')\n",
    "        rating = data.get('rating', '0')\n",
    "        comment = data.get('comment', '')\n",
    "        followup = data.get('followup', '0')\n",
    "        session_id = data.get('sessionID', '')\n",
    "        \n",
    "        # Log the rating to BigQuery or other storage\n",
    "        print(f\"Rating received: {rating} for session {session_id}\")\n",
    "        \n",
    "        return {\"status\": \"success\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        response.status = 500\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Text completion API endpoint\n",
    "@app.route('/api/complete', method='POST')\n",
    "def text_completion():\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt')\n",
    "        model = data.get('model', 'gpt-3.5-turbo')\n",
    "        max_tokens = data.get('max_tokens', 100)\n",
    "        temperature = data.get('temperature', 0.7)\n",
    "        \n",
    "        if not prompt:\n",
    "            response.status = 400\n",
    "            return {\"error\": \"No prompt provided\"}\n",
    "        \n",
    "        # Call OpenAI API\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Log request to BigQuery if available\n",
    "        if bigquery_client:\n",
    "            _log_to_bigquery(prompt, result)\n",
    "        \n",
    "        # Return formatted response\n",
    "        return {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"text\": result.choices[0].message.content,\n",
    "            \"prompt_tokens\": result.usage.prompt_tokens,\n",
    "            \"completion_tokens\": result.usage.completion_tokens,\n",
    "            \"total_tokens\": result.usage.total_tokens,\n",
    "            \"model\": model\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        response.status = 500\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Markdown processing endpoint\n",
    "@app.route('/api/markdown', method='POST')\n",
    "def process_markdown():\n",
    "    try:\n",
    "        data = request.json\n",
    "        markdown_text = data.get('markdown', '')\n",
    "        \n",
    "        if not markdown_text:\n",
    "            response.status = 400\n",
    "            return {\"error\": \"No markdown provided\"}\n",
    "        \n",
    "        # Parse markdown to HTML\n",
    "        html_result = md.render(markdown_text)\n",
    "        \n",
    "        return {\n",
    "            \"html\": html_result,\n",
    "            \"length\": len(html_result)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        response.status = 500\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Store file in GCS\n",
    "@app.route('/api/upload', method='POST')\n",
    "def upload_file():\n",
    "    try:\n",
    "        if not storage_client:\n",
    "            response.status = 503\n",
    "            return {\"error\": \"GCS storage not configured\"}\n",
    "            \n",
    "        file_data = request.files.get('file')\n",
    "        if not file_data:\n",
    "            response.status = 400\n",
    "            return {\"error\": \"No file provided\"}\n",
    "        \n",
    "        file_name = file_data.filename\n",
    "        file_content = file_data.file.read()\n",
    "        content_type = file_data.content_type\n",
    "        \n",
    "        bucket = storage_client.bucket(config[\"storage_bucket\"])\n",
    "        blob = bucket.blob(f\"uploads/{datetime.now().strftime('%Y%m%d')}/{file_name}\")\n",
    "        blob.upload_from_string(file_content, content_type=content_type)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"file_name\": file_name,\n",
    "            \"url\": f\"gs://{config['storage_bucket']}/{blob.name}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        response.status = 500\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Helper function to log to BigQuery\n",
    "def _log_to_bigquery(prompt, response):\n",
    "    try:\n",
    "        table_id = f\"{config['gcp_project_id']}.apilog.requests\"\n",
    "        \n",
    "        row = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"prompt\": prompt,\n",
    "            \"model\": response.model,\n",
    "            \"tokens\": response.usage.total_tokens,\n",
    "            \"session_id\": str(uuid.uuid4())\n",
    "        }\n",
    "        \n",
    "        errors = bigquery_client.insert_rows_json(table_id, [row])\n",
    "        if errors:\n",
    "            print(f\"BigQuery insert errors: {errors}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to log to BigQuery: {e}\")\n",
    "\n",
    "# Run the server if executed directly\n",
    "if __name__ == '__main__':\n",
    "    # Print information about the server\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Running in Jupyter notebook environment\")\n",
    "    print(f\"Static folder: {config['static_folder']}\")\n",
    "    print(f\"File directory: {os.getcwd()}\")\n",
    "    print(f\"Static folder: {config['static_folder']}\")\n",
    "    print(\"Starting API server on port 5010...\")\n",
    "    run(app, host='0.0.0.0', port=int(os.environ.get('PORT', 5010)), debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TicketAI for Finch (v1.11.0)\n",
    "\n",
    "## Overview\n",
    "\n",
    "TicketAI is a support tool designed to assist customer support agents in providing responses to customer queries based on predefined knowledge base entries. It leverages OpenAI's API and integrates with Google Cloud Platform (GCP) services to retrieve relevant vehicle data and operational context for each query. The tool is built using the Bottle web framework and supports interactions with BigQuery and Google Cloud Storage.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Integration with OpenAIâ€™s Azure API for generating automated responses.\n",
    "- Queries GCP services (BigQuery, Storage) for vehicle data and subscriptions.\n",
    "- Uses a Markdown-based knowledge base for predefined customer support templates.\n",
    "- Logs queries, responses, and processing times into BigQuery for tracking and analysis.\n",
    "- Allows support agents to update the knowledge base dynamically from GCP Storage.\n",
    "- Supports vehicle identification through VIN lookups and retrieves detailed vehicle context.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.x\n",
    "- Google Cloud Project with BigQuery, Cloud Storage, and Secret Manager enabled.\n",
    "- OpenAI API key and Azure OpenAI setup.\n",
    "- GCP credentials (stored as environment variables).\n",
    "- Bottle framework.\n",
    "\n",
    "## Environment Variables\n",
    "\n",
    "The application relies on several environment variables to function correctly:\n",
    "\n",
    "| Variable             | Description                                                   |\n",
    "|----------------------|---------------------------------------------------------------|\n",
    "| `GCP_PROJECT`        | Google Cloud project name.                                    |\n",
    "| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI API endpoint.                                    |\n",
    "| `AZURE_OPENAI_KEY`    | Azure OpenAI API key.                                         |\n",
    "| `GCP_DATASET`        | Name of the BigQuery dataset used for logging stats.           |\n",
    "| `GCS_BUCKET_NAME`    | Name of the GCS bucket where knowledge base files are stored.  |\n",
    "| `TOOL_DEBUG`         | Debug flag to enable or disable detailed logs.                 |\n",
    "\n",
    "## Endpoints\n",
    "\n",
    "### `/`\n",
    "\n",
    "- **Method**: `GET`\n",
    "- **Description**: Returns the main page with software information and the agent's email.\n",
    "\n",
    "### `/process_ticket`\n",
    "\n",
    "- **Method**: `POST`\n",
    "- **Description**: Processes a customer query and returns a suggested response from the knowledge base.\n",
    "- **Request Payload**:\n",
    "  ```json\n",
    "  {\n",
    "    \"query\": \"<customer query>\",\n",
    "    \"responseType\": \"customer\", // or \"agent\"\n",
    "    \"deployment\": \"<model deployment (optional)>\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "# Run the server if executed directly\n",
    "if __name__ == '__main__':\n",
    "    # Determine the current directory to properly serve static files\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"File directory: {os.path.dirname(os.path.abspath(__file__))}\")\n",
    "    \n",
    "    # Start server on port 5010\n",
    "    print(\"Starting API server on port 5010...\")\n",
    "    run(app, host='0.0.0.0', port=int(os.environ.get('PORT', 5010)), debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
